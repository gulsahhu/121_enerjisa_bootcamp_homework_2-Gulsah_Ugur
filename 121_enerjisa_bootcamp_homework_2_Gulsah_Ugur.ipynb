{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "121_enerjisa_bootcamp_homework_2-Gulsah_Ugur.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc5olfK4UFCP"
      },
      "source": [
        "#**Gülşah Uğur**#\n",
        "\n",
        "**HW 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM7f8wIXUDbu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "#for quick viz\n",
        "import seaborn as sns\n",
        "\n",
        "#ml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgit4srkTpJy"
      },
      "source": [
        "# **Soru 1**# \n",
        "**One hot encoding modelin görmediği veriye nasıl uygulanır?**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ro1G_OPH7_V"
      },
      "source": [
        "**One Hot Encoding**\n",
        "\n",
        "One-Hot Encoding, kategorik değişkenlerin ikili vektörler olarak temsil edilmesini sağlar.Bu kategorik değerler ilk olarak tamsayı değerlere eşlenir. Her bir tamsayı değeri daha sonra tamamı 0 olan bir ikili vektör olarak temsil edilir.\n",
        "Aşağıdaki durumlarda One-Hot Encoding uygularız:\n",
        "- Kategorik özellik sıralı değildir\n",
        "- Kategorik özelliklerin sayısı daha azdır, bu nedenle One-Hot Encoding etkili bir şekilde uygulanabilir.\n",
        "\n",
        "Verimizi modele sokabilmek için train-test ve validation olmak üzere üç bölüme ayırırız. Burada önemli olan verimizi train-test kısmında hangi aşamalardan geçirdiysek, validation kısmının da aynı aşamalardan geçmiş olması gerekiyor. Burada yaşadığımız en önemli sorunlardan biri One-Hot-Encoding işlemi train-test ve daha sonra validation kısmına uygulandıktan sonra tahminleme de hata almamız. Bunun ana sebebi train-test verisi üzerinde yaptığımız One-Hot-Encoding işlemi sonucunda ortaya çıkan kolonların sayısı ile validation verisi üzerinde yaptığımız One-Hot-Encoder işlemi sonucunda ortaya çıkan kolon sayısının eşit olmamasından kaynaklı modelin validation kısmında hata vermesi. Bu sorunun çözümüne ilişkin; modelin görmediği verisi için *OneHotEncoder*'ın ***handle_unknown*** parametresini ***ignore*** olarak ayarlayarak dönüşüm sırasında farklı olarak bilinmeyen bir kategoriyle karşılaşırsa o kategori bu parametre ile yok sayılabilir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkHV4AvtOkqF"
      },
      "source": [
        " from sklearn.preprocessing import OneHotEncoder\n",
        " enc = OneHotEncoder(handle_unknown='ignore')\n",
        " X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
        " enc.fit(X)\n",
        " enc.categories_\n",
        " enc.transform([['Female', 1], ['Male', 4]]).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Vr6GXbYObh"
      },
      "source": [
        "# **Soru 2**# \n",
        "**Labelencoding'de ilgili kolon için ölçeklendirme nasıl yapılır? (Verinin doğru etkisiyle sayısal olarak dönüştürülmesi)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FkmLTvKP8eH"
      },
      "source": [
        "**Label Encoding**\n",
        "\n",
        "Label Encoding’de, her bir veri için alfabetik sıralamaya göre benzersiz bir tam sayı atanır. Örneğin cinsiyet değişkeninde eşsiz iki değer vardır: Female ve Male. F alfabetik olarak daha önde olduğu için Female 0, Male 1 değerini alır. Eğitim değişkenine ait veriler Ordinal Kategoriktir. Yani aralarında hiyerarşik bir sıra vardır.\n",
        "Aşağıdaki durumlarda Label Encoding uygularız:\n",
        "- Kategorik özellik sıralıdır\n",
        "- Tek etkin kodlama yüksek bellek tüketimine yol açabileceğinden kategori sayısı oldukça fazladır."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "pKKrnQq6Sff_",
        "outputId": "ed821ebf-d5e4-47ac-b670-d7765bf48f27"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
        "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
        "labelencoder = LabelEncoder()\n",
        "bridge_df['Bridge_Types_Cat'] = labelencoder.fit_transform(bridge_df['Bridge_Types'])\n",
        "bridge_df"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bridge_Types</th>\n",
              "      <th>Bridge_Types_Cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arch</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beam</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Truss</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cantilever</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tied Arch</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Suspension</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Cable</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Bridge_Types  Bridge_Types_Cat\n",
              "0         Arch                 0\n",
              "1         Beam                 1\n",
              "2        Truss                 6\n",
              "3   Cantilever                 3\n",
              "4    Tied Arch                 5\n",
              "5   Suspension                 4\n",
              "6        Cable                 2"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYo6FoIxYjBn"
      },
      "source": [
        "# **Soru 3**# \n",
        "\n",
        "**Imbalance datasette train test split yaparken neleri göz önünde bulundurmalıyız?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XA7QPO3Yqcu"
      },
      "source": [
        "**Dengesiz Veri Kümesi Nedir?**\n",
        "\n",
        "Sınıflandırma yaparken, sınıfların eşit dağılmadığı, yani her sınıf için yaklaşık olarak aynı sayıda verinin olmadığı veri kümesidir.Dengesiz veri kümeleriyle karşılaştığımız durumlarda birçok makine öğrenmesi algoritması, sınıflardaki eşit olmayan dağılımı dikkate almayarak güvenilir sonuçlar vermeyebiliyor. Bu nedenden ötürü dengesiz veri kümeleriyle çalışırken dikkat etmemiz gereken noktalar ön plana çıkabiliyor;\n",
        "- Dengesiz veri kümelerini, eğitim veri kümesi ve test veri kümesi olarak ikiye ayırırken, verilerin dengesizlik oranında, eğitim ve test kümelerine eşit dağılması gerekir. Yani her iki kümede sınıfların oranının aynı olması, modelin performansının istikrarlı olması açısından önemli. Dolayısıyla, veri kümesini eğitim ve test veri kümelerine ayırırken, train_test_split() fonksiyonundaki “stratify” parametresini dikkate almak gerekiyor.\n",
        "- Makine öğrenmesi algoritmalarını eğitmek için kullandığımız scikit-learn kütüphanesinin içindeki birçok sınıflandırıcı \"class_weight\" parametresine sahip.Dengesiz bir veri kümesi, “class_weight” parametresi yardımıyla azınlık sınıfına atanan ağırlığı dengesizlik oranında arttırarak, algoritmanın azınlık verisini yanlış sınıflandırmasından kaynaklanan hata oranını arttırabilir. Dolayısıyla, modeli oluştururken genel hata oranını (overall error rate) azaltmaya çalışan algoritma bu dengesizliği, yani azınlık sınıfı dikkate alacak ve performansı artacaktır.\n",
        "- Penalized Sınıflandırma yöntemleri (penalized-SVM and penalized-LDA, logistik regresyon vs.) modele, algoritmaları eğitirken, yanlış sınıflandırılan azınlık sınıfı verileri için fazladan cost yüklediği için, modelin azınlık sınıfına verdiği ağırlığı arttırıyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XwjuzTZe07q"
      },
      "source": [
        "# **Soru 4**# \n",
        "**Validation dataseti (modelin görmediği) nasıl oluşturulur ve nasıl predict etmeye hazır hale getirilir?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwDy_lu1e-kq"
      },
      "source": [
        "**Validation Veri Seti**\n",
        "\n",
        "Validation bölümü train veri seti içinden seçilir. Train veri seti üzerinde doğru model seçimi yapılarak algoritma belirlenir. Validation bölümünde ise uygulanan model iyileştirilmeye çalışılır. Bunun için hiper parametrik (hyperparameter tuning) uygulamalar denenerek en optimum katsayılar/ağırlıklar bulunmaya çalışılır. Özellikle çok büyük veri setleri üzerinde sürekli Train datası üzerinden çalışılamayacağı için küçük bir bölüm alınarak validation olarak tanımlanır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsdBcqklxRV"
      },
      "source": [
        "# **Soru 5**# \n",
        "**predict_proba metoduyla oran nasıl hesaplanır ve threshold nasıl değiştirilir?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsTmDcL6nMwk"
      },
      "source": [
        "Oluşturduğunuz modelleri eğittikten sonra sonuçları elde etmek için kullanabileceğiniz iki farklı fonksiyon tipi var.\n",
        "- *predict*: Regresyon, sınıflandırma, kümeleme gibi yöntemler kullanarak yapacağımız çalışmalarda tahmin edilen etiket bilgisini predict fonksiyonuyla elde edebiliriz. Sınıflandırma problemlerinde gözlemlerin sınıflara ait olma olasılıklarını elde etmek istiyorsanız *predict_proba* fonksiyonunu kullanmanız gerekiyor.\n",
        "\n",
        "`y_pred = dt.predict(X_test)`\n",
        "\n",
        "Eğer etiketleri değil de olasılıkları öğrenmek istiyorsak predict_proba fonksiyonunu kullanmamız gerekiyor. Sonuçlar her etikete ait olma yüzdesini içeriyor.\n",
        "\n",
        "`y_pred_proba = dt.predict_proba(X_test)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um4UJZBlunpX"
      },
      "source": [
        "rfc = RandomForestClassifier(random_state = 1)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred = (rfc.predict_proba(X_test)[:,1] >= 0.4).astype(bool) \n",
        "# Normalde threshold değerimiz default olarak 0.5 alınıyorken, 0.4 olarak değiştirdik.\n",
        "score = rfc.score(X_test, y_test)\n",
        "print(score)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sx54byvTXdt"
      },
      "source": [
        "# **Soru 6**# \n",
        "**Fraud case'i üzerinde train&test&validation split, encoding, scaling,modelleme çalışmaları Python'da yapılarak, modelin görmediği dataset üzerinde başarılı sonuç alacak bir model örneği yapılmalı.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wLVjzS8Tqf-",
        "outputId": "0c288f96-d880-4dfa-f3e9-813c325c6adc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT6-Dg-lTwo-"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/auto_insurance_csv.csv')\n",
        "df = df.drop(['_c39','Unnamed: 0'], axis = 1)\n",
        "df['umbrella_limit'] = df.umbrella_limit.fillna(\"9999\")\n",
        "df['police_report_available'] = df.police_report_available.fillna(\"MISSING\")\n",
        "df['policy_csl'] = df.policy_csl.fillna(\"MISSING\")\n",
        "df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'])\n",
        "df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
        "df['claim_day_of_policy'] = (df.incident_date -  df.policy_bind_date).dt.days\n",
        "df['location_check'] = np.nan\n",
        "df['location_check'] = np.where(df['policy_state'] == df['incident_state'], True, False)\n",
        "df['fraud_reported'] = df['fraud_reported'].str.replace('Y', '1')\n",
        "df['fraud_reported'] = df['fraud_reported'].str.replace('N', '0')\n",
        "df['fraud_reported'] = df['fraud_reported'].astype(int)\n",
        "df['umbrella_limit'] = df.umbrella_limit.astype(str)\n",
        "umbrealla = df['umbrella_limit'].unique()\n",
        "for umb in umbrealla:\n",
        "  if (umb != '0.0') & (umb != '9999'):\n",
        "    df['umbrella_limit'] = df['umbrella_limit'].str.replace(umb, 'other')\n",
        "    \n",
        "hobbies = df['insured_hobbies'].unique()\n",
        "for hobby in hobbies:\n",
        "  if (hobby != 'chess') & (hobby != 'cross-fit'):\n",
        "    df['insured_hobbies'] = df['insured_hobbies'].str.replace(hobby, 'other')\n",
        "\n",
        "df['age'] = df.age.fillna(9999)\n",
        "bin_labels = ['15-20', '21-25', '26-30', '31-35', '36-40', '41-45', '46-50', '51-55', '56-60', '61-65','9999']\n",
        "bins = [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 9999]\n",
        "\n",
        "df['age_group'] = pd.cut(df['age'], bins = bins, labels = bin_labels, include_lowest = True)\n",
        "bins = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "bin_labels = ['0-50','51-100','101-150','151-200','201-250','251-300','301-350','351-400','401-450','451-500']\n",
        "\n",
        "df['months_as_customer_groups'] = pd.cut(df['months_as_customer'], bins = 10, labels = bin_labels, include_lowest= True)\n",
        "bins = list(np.linspace(0,2500, 6, dtype = int))\n",
        "bin_labels = ['very low', 'low', 'medium', 'high', 'very high']\n",
        "\n",
        "df['policy_annual_premium_groups'] = pd.cut(df['policy_annual_premium'], bins = bins, labels=bin_labels)\n",
        "bins = list(np.linspace(0,2000, 5, dtype = int))\n",
        "bin_labels = ['0-500', '501-1000', '1001-1500', '1501-2000']\n",
        "\n",
        "df['policy_deductable_group'] = pd.cut(df['policy_deductable'], bins = bins, labels = bin_labels)\n",
        "\n",
        "df = df.drop(['age', 'months_as_customer', 'policy_deductable', 'policy_annual_premium'], axis = 1)\n",
        "required_columns = ['incident_date','policy_state', 'policy_csl', 'umbrella_limit',\n",
        "       'insured_zip', 'insured_sex', 'insured_education_level',\n",
        "       'insured_occupation', 'insured_hobbies', 'insured_relationship',\n",
        "       'capital-gains', 'capital-loss', 'incident_type', 'collision_type',\n",
        "       'incident_severity', 'authorities_contacted', 'incident_state',\n",
        "       'incident_city', 'incident_location', 'incident_hour_of_the_day',\n",
        "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
        "       'witnesses', 'police_report_available', 'total_claim_amount','auto_make',\n",
        "       'auto_model', 'auto_year', 'fraud_reported', 'claim_day_of_policy',\n",
        "       'location_check', 'age_group', 'months_as_customer_groups',\n",
        "       'policy_annual_premium_groups', 'policy_deductable_group']\n",
        "df1 = df[required_columns]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsq_Y4usb-qy",
        "outputId": "b485a0f8-8510-43b0-ad76-abd55e9327c6"
      },
      "source": [
        "df1.incident_date.count()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAyZGp_hxNeH"
      },
      "source": [
        "**TRAIN-TEST VE VALIDATION KISIMLARININ AYRILMASI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J05FIOHQVg8_"
      },
      "source": [
        "# Verimiz normal dağılım gösterdiği için ayırma yöntemini istediğim şekilde yapabilirim. Burada ki kodda veriler sıraladıktan sonra en büyük 200 değer validation olarak tutulacak.\n",
        "df1_val = df1.sort_values(by='incident_date',ascending=False).head(200)\n",
        "df1_ttdata = df1.sort_values(by='incident_date',ascending=False).tail(800)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZIJd8Y0ViWG"
      },
      "source": [
        "# Gereksiz kolonların temizlenmesi\n",
        "df1_val = df1_val.drop([\"incident_date\"],axis=1)\n",
        "df1_ttdata = df1_ttdata.drop([\"incident_date\"],axis=1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3e5FAoUc2Zn"
      },
      "source": [
        "df1_val = df1_val.drop([\"incident_location\"],axis=1)\n",
        "df1_ttdata = df1_ttdata.drop([\"incident_location\"],axis=1)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn8EuCpiVtYg",
        "outputId": "dc9af81e-d90f-4218-f406-8d3a1fa0565e"
      },
      "source": [
        "# Kategorik Değişkenler\n",
        "cat_cols = ['age_group', 'months_as_customer_groups', 'policy_annual_premium_groups','location_check','policy_deductable_group']\n",
        "for col in cat_cols:\n",
        "  df1_ttdata[col] = df1_ttdata[col].astype('object')\n",
        "\n",
        "columns_to_encode = []\n",
        "for col in df1_ttdata.columns:\n",
        "  if df1_ttdata[col].dtype == 'object':\n",
        "    columns_to_encode.append(col)\n",
        "\n",
        "columns_to_encode"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['policy_state',\n",
              " 'policy_csl',\n",
              " 'umbrella_limit',\n",
              " 'insured_sex',\n",
              " 'insured_education_level',\n",
              " 'insured_occupation',\n",
              " 'insured_hobbies',\n",
              " 'insured_relationship',\n",
              " 'incident_type',\n",
              " 'collision_type',\n",
              " 'incident_severity',\n",
              " 'authorities_contacted',\n",
              " 'incident_state',\n",
              " 'incident_city',\n",
              " 'property_damage',\n",
              " 'police_report_available',\n",
              " 'auto_make',\n",
              " 'auto_model',\n",
              " 'location_check',\n",
              " 'age_group',\n",
              " 'months_as_customer_groups',\n",
              " 'policy_annual_premium_groups',\n",
              " 'policy_deductable_group']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmTcBIokWsUn"
      },
      "source": [
        "columns_to_encode= []\n",
        "for col in df1_ttdata.columns:\n",
        "  if df1_ttdata[col].dtype == 'object':\n",
        "    columns_to_encode.append(col)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pVj7Rrbe_7S"
      },
      "source": [
        "df1_ttdata_dummy = pd.get_dummies(df1_ttdata, columns = columns_to_encode)\n",
        "columns_dummy = []\n",
        "for i in df1_ttdata_dummy.columns:\n",
        "    columns_dummy.append(i)\n",
        "\n",
        "df1_dummy = df1_ttdata_dummy.iloc[:,:11]\n",
        "clmn_dummy= columns_dummy[11:]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "kwbXuPE6fjss",
        "outputId": "ff79648f-3c5f-4d73-9276-6a5536eee41d"
      },
      "source": [
        "#One-Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_fit = ohe.fit(df1_ttdata[columns_to_encode])\n",
        "enc_fit_arr=enc_fit.fit_transform(df1_ttdata[columns_to_encode]).toarray()\n",
        "enc_fit_df=pd.DataFrame(enc_fit_arr, columns=clmn_dummy)\n",
        "df1_dummy.reset_index(drop=True, inplace=True)\n",
        "df1_ttdata_ohe = pd.concat([df1_dummy,enc_fit_df], axis=1)\n",
        "df1_ttdata_ohe.head(14)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>insured_zip</th>\n",
              "      <th>capital-gains</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>incident_hour_of_the_day</th>\n",
              "      <th>number_of_vehicles_involved</th>\n",
              "      <th>bodily_injuries</th>\n",
              "      <th>witnesses</th>\n",
              "      <th>total_claim_amount</th>\n",
              "      <th>auto_year</th>\n",
              "      <th>fraud_reported</th>\n",
              "      <th>claim_day_of_policy</th>\n",
              "      <th>policy_state_IL</th>\n",
              "      <th>policy_state_IN</th>\n",
              "      <th>policy_state_OH</th>\n",
              "      <th>policy_csl_100/300</th>\n",
              "      <th>policy_csl_250/500</th>\n",
              "      <th>policy_csl_500/1000</th>\n",
              "      <th>policy_csl_MISSING</th>\n",
              "      <th>umbrella_limit_0.0</th>\n",
              "      <th>umbrella_limit_9999</th>\n",
              "      <th>umbrella_limit_other</th>\n",
              "      <th>insured_sex_FEMALE</th>\n",
              "      <th>insured_sex_MALE</th>\n",
              "      <th>insured_education_level_Associate</th>\n",
              "      <th>insured_education_level_College</th>\n",
              "      <th>insured_education_level_High School</th>\n",
              "      <th>insured_education_level_JD</th>\n",
              "      <th>insured_education_level_MD</th>\n",
              "      <th>insured_education_level_Masters</th>\n",
              "      <th>insured_education_level_PhD</th>\n",
              "      <th>insured_occupation_adm-clerical</th>\n",
              "      <th>insured_occupation_armed-forces</th>\n",
              "      <th>insured_occupation_craft-repair</th>\n",
              "      <th>insured_occupation_exec-managerial</th>\n",
              "      <th>insured_occupation_farming-fishing</th>\n",
              "      <th>insured_occupation_handlers-cleaners</th>\n",
              "      <th>insured_occupation_machine-op-inspct</th>\n",
              "      <th>insured_occupation_other-service</th>\n",
              "      <th>insured_occupation_priv-house-serv</th>\n",
              "      <th>insured_occupation_prof-specialty</th>\n",
              "      <th>...</th>\n",
              "      <th>auto_model_RAM</th>\n",
              "      <th>auto_model_RSX</th>\n",
              "      <th>auto_model_Silverado</th>\n",
              "      <th>auto_model_TL</th>\n",
              "      <th>auto_model_Tahoe</th>\n",
              "      <th>auto_model_Ultima</th>\n",
              "      <th>auto_model_Wrangler</th>\n",
              "      <th>auto_model_X5</th>\n",
              "      <th>auto_model_X6</th>\n",
              "      <th>location_check_False</th>\n",
              "      <th>location_check_True</th>\n",
              "      <th>age_group_15-20</th>\n",
              "      <th>age_group_21-25</th>\n",
              "      <th>age_group_26-30</th>\n",
              "      <th>age_group_31-35</th>\n",
              "      <th>age_group_36-40</th>\n",
              "      <th>age_group_41-45</th>\n",
              "      <th>age_group_46-50</th>\n",
              "      <th>age_group_51-55</th>\n",
              "      <th>age_group_56-60</th>\n",
              "      <th>age_group_61-65</th>\n",
              "      <th>age_group_9999</th>\n",
              "      <th>months_as_customer_groups_0-50</th>\n",
              "      <th>months_as_customer_groups_101-150</th>\n",
              "      <th>months_as_customer_groups_151-200</th>\n",
              "      <th>months_as_customer_groups_201-250</th>\n",
              "      <th>months_as_customer_groups_251-300</th>\n",
              "      <th>months_as_customer_groups_301-350</th>\n",
              "      <th>months_as_customer_groups_351-400</th>\n",
              "      <th>months_as_customer_groups_401-450</th>\n",
              "      <th>months_as_customer_groups_451-500</th>\n",
              "      <th>months_as_customer_groups_51-100</th>\n",
              "      <th>policy_annual_premium_groups_high</th>\n",
              "      <th>policy_annual_premium_groups_low</th>\n",
              "      <th>policy_annual_premium_groups_medium</th>\n",
              "      <th>policy_annual_premium_groups_very high</th>\n",
              "      <th>policy_annual_premium_groups_very low</th>\n",
              "      <th>policy_deductable_group_0-500</th>\n",
              "      <th>policy_deductable_group_1501-2000</th>\n",
              "      <th>policy_deductable_group_501-1000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>446755</td>\n",
              "      <td>0</td>\n",
              "      <td>-46200</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6560</td>\n",
              "      <td>2003</td>\n",
              "      <td>0</td>\n",
              "      <td>4427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>475891</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6000</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>8921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>603948</td>\n",
              "      <td>47200</td>\n",
              "      <td>-69700</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>36300</td>\n",
              "      <td>2013</td>\n",
              "      <td>0</td>\n",
              "      <td>205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>462525</td>\n",
              "      <td>26500</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>55200</td>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1980</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>471366</td>\n",
              "      <td>0</td>\n",
              "      <td>-31700</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>48290</td>\n",
              "      <td>1995</td>\n",
              "      <td>0</td>\n",
              "      <td>7692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>604328</td>\n",
              "      <td>0</td>\n",
              "      <td>-47400</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3190</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>8231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>438546</td>\n",
              "      <td>0</td>\n",
              "      <td>-54600</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>72120</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>3483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>431354</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>48070</td>\n",
              "      <td>2014</td>\n",
              "      <td>0</td>\n",
              "      <td>2591</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>476737</td>\n",
              "      <td>0</td>\n",
              "      <td>-40900</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>70290</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>6798</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>437470</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>42500</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>5385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>610706</td>\n",
              "      <td>66000</td>\n",
              "      <td>-46000</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6500</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>435100</td>\n",
              "      <td>67900</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>58500</td>\n",
              "      <td>1999</td>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>443567</td>\n",
              "      <td>0</td>\n",
              "      <td>-32100</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60200</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>4819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>450800</td>\n",
              "      <td>51100</td>\n",
              "      <td>-75100</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>69400</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>8585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows × 175 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    insured_zip  ...  policy_deductable_group_501-1000\n",
              "0        446755  ...                               1.0\n",
              "1        475891  ...                               0.0\n",
              "2        603948  ...                               1.0\n",
              "3        462525  ...                               0.0\n",
              "4        471366  ...                               0.0\n",
              "5        604328  ...                               0.0\n",
              "6        438546  ...                               0.0\n",
              "7        431354  ...                               0.0\n",
              "8        476737  ...                               0.0\n",
              "9        437470  ...                               1.0\n",
              "10       610706  ...                               1.0\n",
              "11       435100  ...                               0.0\n",
              "12       443567  ...                               1.0\n",
              "13       450800  ...                               0.0\n",
              "\n",
              "[14 rows x 175 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQBfN6vgZxD",
        "outputId": "2cc09b63-2a31-4ea9-ba79-58c4c19a0140"
      },
      "source": [
        "cols = df1_ttdata_ohe.columns\n",
        "num_cols = df1_ttdata_ohe._get_numeric_data().columns\n",
        "list(set(cols) - set(num_cols))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk-B2psRW-9G"
      },
      "source": [
        "# feature ve target seçimi\n",
        "\n",
        "target = 'fraud_reported'\n",
        "\n",
        "X = df1_ttdata_ohe.drop(columns=target, axis=1)\n",
        "y = df1_ttdata_ohe[target]\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxBMXYCWhVhr"
      },
      "source": [
        "#StandartScaler işlemiyle ölçeklendirme yapılması\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "aydaxTs-YM5A",
        "outputId": "d37a3d95-aae1-486b-a6e8-40ef9c8538d3"
      },
      "source": [
        "# SMOTE\n",
        "oversample = SMOTE(random_state=9)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,  random_state = 42)\n",
        "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size = 0.3, random_state = 1)\n",
        "chck = pd.DataFrame()\n",
        "chck['fraud_reported'] = y_train\n",
        "\n",
        "sns.countplot(chck['fraud_reported'])\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
            "\n",
            "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3794bd2690>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "HVvmKTxYYpy4",
        "outputId": "c3a2a530-d02e-4ce9-c859-7b4d11a1bb6c"
      },
      "source": [
        "# Random Forest Modelling\n",
        "rfc = RandomForestClassifier(random_state = 1)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "preds = rfc.predict(X_test)\n",
        "\n",
        "score = rfc.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93.25396825396825\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93       128\n",
            "           1       0.92      0.94      0.93       124\n",
            "\n",
            "    accuracy                           0.93       252\n",
            "   macro avg       0.93      0.93      0.93       252\n",
            "weighted avg       0.93      0.93      0.93       252\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3794c3a190>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6fBbjxhit17",
        "outputId": "c23717d4-3489-4a72-ac9d-4e5629912fc7"
      },
      "source": [
        "# HYPERPARAMETER OPTIMIZATION\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 1000, num = 3)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 3)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [300, 650, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 17, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   30.7s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [5, 17, 30, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [300, 650, 1000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwJZPxPxae1I",
        "outputId": "507cf0de-42a7-4363-b8de-b23d9cbc47e4"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_depth': 5,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 300}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "ypOZw7PllFk1",
        "outputId": "a388672f-7f60-4239-8292-ecd33c2a992c"
      },
      "source": [
        "# Optimize edilen parametreler sonrası Random Forest\n",
        "rf2 = RandomForestClassifier(n_estimators=300,min_samples_split=2,min_samples_leaf=2,max_features='auto'\n",
        "                            ,max_depth=5,bootstrap='False')\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "preds = rf2.predict(X_test)\n",
        "\n",
        "score = rf2.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.85714285714286\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.91      0.93       128\n",
            "           1       0.91      0.95      0.93       124\n",
            "\n",
            "    accuracy                           0.93       252\n",
            "   macro avg       0.93      0.93      0.93       252\n",
            "weighted avg       0.93      0.93      0.93       252\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f37942772d0>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozUKaTYQn6N2"
      },
      "source": [
        "**VALIDATION SETİ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqc5QYWpn92N"
      },
      "source": [
        "# Kategorik Değişkenler\n",
        "categorical_cols = ['age_group', 'months_as_customer_groups', 'policy_annual_premium_groups','location_check','policy_deductable_group']\n",
        "for col in categorical_cols:\n",
        "  df1_val[col] = df1_val[col].astype('object')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-k00nvoTbl"
      },
      "source": [
        "columns_to_encode = []\n",
        "for col in df1_val.columns:\n",
        "  if df1_val[col].dtype == 'object':\n",
        "    columns_to_encode.append(col)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1INOM7XUoskl"
      },
      "source": [
        "#One-Hot Encoding\n",
        "df1_val_ohe = pd.DataFrame(enc_fit.transform(df1_val[columns_to_encode]).toarray(), columns=clmn_dummy)\n",
        "columns_num = columns_dummy[:11]\n",
        "df1_val_numerical = pd.DataFrame(df1_val, columns=columns_num)\n",
        "df1_val_numerical.reset_index(drop=True, inplace=True)\n",
        "df1_val_ohe = pd.concat([df1_val_numerical, df1_val_ohe], axis=1)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3c0Fi65ozw8"
      },
      "source": [
        "# feature ve target seçimi\n",
        "target = 'fraud_reported'\n",
        "X_val = df1_val_ohe.drop(columns=target, axis=1)\n",
        "y_val = df1_val_ohe[target]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNhInuaXoz4L"
      },
      "source": [
        "#StandartScaler işlemiyle ölçeklendirme yapılması\n",
        "sc = StandardScaler()\n",
        "X_val = sc.fit_transform(X_val)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdXyDT2VqCAl",
        "outputId": "bddc39ed-e1d1-49a7-b104-a86590d8ae76"
      },
      "source": [
        "# SMOTE\n",
        "oversample = SMOTE(random_state=20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3,  random_state = 42)\n",
        "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, stratify=y_over, test_size = 0.3, random_state = 1)\n",
        "\n",
        "chck = pd.DataFrame()\n",
        "chck['fraud_reported'] = y_train"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
            "\n",
            "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "lTR3TDfvpSK2",
        "outputId": "d1c2eb41-4c2a-4988-b3ae-8ab415e056db"
      },
      "source": [
        "# Validation seti ile Random Forest\n",
        "rfc = RandomForestClassifier(random_state = 1)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "preds = rfc.predict(X_test)\n",
        "\n",
        "score = rfc.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.7258064516129\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91       124\n",
            "           1       0.91      0.90      0.91       124\n",
            "\n",
            "    accuracy                           0.91       248\n",
            "   macro avg       0.91      0.91      0.91       248\n",
            "weighted avg       0.91      0.91      0.91       248\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f37938e6910>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUX5S2xAtA6m",
        "outputId": "2196abc4-e9eb-4c4d-9b0b-2f4054b8f171"
      },
      "source": [
        "# HYPERPARAMETER OPTIMIZATION\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 15)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 9)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10, 15]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [100, 164, 228, 292, 357, 421, 485, 550, 614, 678, 742, 807, 871, 935, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 8, 11, 14, 17, 20, 23, 26, 30, None], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   39.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.3min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [5, 8, 11, 14, 17, 20, 23,\n",
              "                                                      26, 30, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10, 15],\n",
              "                                        'n_estimators': [100, 164, 228, 292,\n",
              "                                                         357, 421, 485, 550,\n",
              "                                                         614, 678, 742, 807,\n",
              "                                                         871, 935, 1000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh1VwsrTuJb3",
        "outputId": "69a2360a-6451-40c1-f4ec-62be40d2fd08"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_depth': 20,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 15,\n",
              " 'n_estimators': 614}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "zqEI3B2BuROG",
        "outputId": "763ad398-afc5-4582-ffaf-f20c6cb8d034"
      },
      "source": [
        "# Validation seti ile Optimize edilen parametreler sonrası Random Forest\n",
        "rf2 = RandomForestClassifier(n_estimators=807,min_samples_split=2,min_samples_leaf=1,max_features='auto'\n",
        "                            ,max_depth=26,bootstrap='True')\n",
        "rf2.fit(X_train, y_train)\n",
        "\n",
        "preds = rf2.predict(X_test)\n",
        "\n",
        "score = rf2.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.93548387096774\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       124\n",
            "           1       0.92      0.92      0.92       124\n",
            "\n",
            "    accuracy                           0.92       248\n",
            "   macro avg       0.92      0.92      0.92       248\n",
            "weighted avg       0.92      0.92      0.92       248\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3793697bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "QrClEAwivutP",
        "outputId": "9dfc42ff-3a05-447b-c67d-5b72c08577b2"
      },
      "source": [
        "# THRESHOLD değer değiştirme\n",
        "rf2 = RandomForestClassifier(n_estimators=807,min_samples_split=2,min_samples_leaf=1,max_features='auto'\n",
        "                            ,max_depth=26,bootstrap='True')\n",
        "rf2.fit(X_train, y_train)\n",
        "preds = (rf2.predict_proba(X_test)[:,1] >= 0.3).astype(bool) \n",
        "score = rf2.score(X_test, y_test)\n",
        "print(score*100)\n",
        "print()\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "sns\n",
        "sns.heatmap(cm, annot=True)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.53225806451613\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.91       124\n",
            "           1       0.87      0.98      0.92       124\n",
            "\n",
            "    accuracy                           0.92       248\n",
            "   macro avg       0.92      0.92      0.92       248\n",
            "weighted avg       0.92      0.92      0.92       248\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f379330a890>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}